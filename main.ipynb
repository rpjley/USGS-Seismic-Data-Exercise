{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercise SEP Developer Test**"
      ],
      "metadata": {
        "id": "TJe6BmxN3Plw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This test is designed to assess your ability to design and develop a project from a limited set of goals, provided below. We will evaluate your project based on its fulfillment of the outlined objectives, code efficiency, readability, and adherence to best practices. Additionally, we will evaluate the structure and content of your GitHub repository according to standard practices.\n",
        "\n",
        "1. Please perform all coding within the Google Colab environment: http://colab.research.google.com\n",
        "    * Please store your project in a GitHub repository, so we can fork and run it in Colab.\n",
        "        * Additionally, please create a standard GitHub repository with the expected files and directory structure.    \n",
        "    * Please note that Colab doesn't automatically include additional files. To avoid potential issues, we recommend only including files that the evaluators already have access to.    \n",
        "    * The evaluators will use the files SEP01.mseed, SEP02.mseed, and SEP03.mseed, which can be found in this GitHub project.\n",
        "2. Import the mseed files\n",
        "3. Create a database with proper normal form and constraints\n",
        "4. Import the data into the newly created database\n",
        "5. Create a visualization for the data. The visualization can be static but must include:    \n",
        "    * A title\n",
        "    * Text section displaying metadata about the miniseed data\n",
        "    * Helicorder-style charts of the miniseed data (These may be built from the database data or the mseed files)\n",
        "    * A map with icons indicating station locations based on the miniseed data (station lat and lon can be found on iris' API)\n",
        "    * Add to the map additional stations found on IRIS' data API. Stations of interest include HOA and SUG\n",
        "        * Data API information can be found at http://service.iris.edu/fdsnws/station/1/\n",
        "\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "a5f77d4a004bc4ad"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Environment Setup**\n"
      ],
      "metadata": {
        "id": "LoRlM_-IEXnl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Overview**"
      ],
      "metadata": {
        "id": "-56ONW4NsHo1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section installs all necessary packages used to run the code. Please run the **Installation Code** section to install all necessary packages for the current session.\n",
        "\n",
        "Packages used in this project include:\n",
        "- **ObsPy** - used for seismic data processing and analysis.\n",
        "- **Folium** - used for creating interactive maps of seismic station locations.\n",
        "- **SQLAlchemy** (installed via ObsPy) - supports database operations for managing seismic station and waveform data."
      ],
      "metadata": {
        "id": "_Y8Zu14Tr12X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Installation Code**"
      ],
      "metadata": {
        "id": "0GiT6OIVsBCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary quietly\n",
        "!pip install -q obspy folium > /dev/null 2>&1\n",
        "# Confirm successful installation\n",
        "print(\"All Packages Successfully Installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fFAgoJexEbML",
        "outputId": "045e67d9-1423-4b11-d3ca-329cc19f62ca"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All Packages Successfully Installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Database Creation**\n"
      ],
      "metadata": {
        "id": "mnwTHcnMG7lW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Overview**"
      ],
      "metadata": {
        "id": "YKJmntwsuuyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section initializes and tests the database creation functions. Be sure to run the **Database Creation Code** section to set up the database functions for the current session.\n",
        "\n",
        "The database is built using SQLAlchemy, which integrates seamlessly with Python objects. It is configured as a file-based structure named seismic_data.db. Unit tests are included to verify the database structure and ensure querying functionality operates as expected.\n",
        "\n",
        "\n",
        "#### **Database Structure**\n",
        "\n",
        "1. **Station Table**:\n",
        "- Stores metadata about seismic stations.\n",
        "- Columns:\n",
        " - `station_id`: Unique identifier for each station (Primary Key).\n",
        " - `station`: Name of the station.\n",
        " - `network`: Network code.\n",
        " - `channel`: Channel code (e.g., EHZ).\n",
        " - `latitude`: Latitude of the station.\n",
        " - `longitude`: Longitude of the station.\n",
        "\n",
        "2. **WaveformTrace Table**:\n",
        "- Stores individual seismic waveform traces.\n",
        "- Columns:\n",
        " - `trace_id`: Unique identifier for each trace (Primary Key).\n",
        " - `station_id`: Links to the corresponding station (Foreign Key).\n",
        " - `start_time`: Start time of the trace.\n",
        " - `end_time`: End time of the trace.\n",
        " - `trace_data`: Serialized binary data of the waveform.\n",
        " - `sampling_rate`: Sampling rate of the waveform in Hz.\n",
        "\n",
        "#### **Database Functions**\n",
        "\n",
        "1. **setup_database**()\n",
        "\n",
        "- Initializes a SQLite database with tables for Station and WaveformTrace.\n",
        "Configures the database as a file-based structure (seismic_data.db) and returns an engine and session for interaction.\n",
        "\n",
        "2. **initialize_database**(stream, session)\n",
        "\n",
        "- Populates the database using an ObsPy Stream object.\n",
        "Adds station metadata if it is not already in the database and stores individual seismic waveform traces, including metadata like sampling rate and timestamps.\n",
        "\n",
        "3. **get_coordinates**(station_name)\n",
        "\n",
        "- Retrieves latitude and longitude coordinates for a station using the IRIS data API.\n",
        "If unavailable via IRIS, prompts the user to manually input the missing coordinates.\n",
        "\n",
        "#### **Database Unit Tests Functions**\n",
        "\n",
        "1. **setup_database**()\n",
        "\n",
        "- Sets up the database for unit testing by creating tables for Station and WaveformTrace.\n",
        "Uses the file-based structure (seismic_data.db) for accurate testing.\n",
        "\n",
        "2. **test_full_trace_count**()\n",
        "\n",
        "- Confirms all traces from the ObsPy Stream are stored in the database.\n",
        "Validates that the total number of traces matches the expected count.\n",
        "\n",
        "3. **test_query_by_time_range**()\n",
        "\n",
        "- Tests the ability to query traces by a specific time range.\n",
        "Verifies that the number of returned traces aligns with the expected results for the queried window.\n",
        "\n",
        "4. **test_query_by_station**()\n",
        "\n",
        "- Ensures that the database correctly filters traces by station name.\n",
        "Confirms all retrieved traces belong to the specified station.\n",
        "\n",
        "5. **test_query_by_sampling_rate**()\n",
        "\n",
        "- Checks the filtering of traces by sampling rate.\n",
        "Validates that all retrieved traces match the given sampling rate.\n",
        "\n",
        "6. **test_query_by_channel**()\n",
        "\n",
        "- Verifies the database can filter traces by channel.\n",
        "Ensures all returned traces belong to the queried channel.\n",
        "\n",
        "7. **test_query_by_location**()\n",
        "\n",
        "- Confirms the ability to filter traces by geographic coordinates (latitude and longitude).\n",
        "Validates that the returned traces correspond to the specified location.\n",
        "\n",
        "8. **test_validate_trace_metadata**()\n",
        "\n",
        "- Verifies the integrity of trace metadata stored in the database.\n",
        "Checks values like start time, end time, sampling rate, and data length against known expected values to ensure accuracy."
      ],
      "metadata": {
        "id": "695MKgChuynC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Database Creation Code**"
      ],
      "metadata": {
        "id": "LWZVDptShpkg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from obspy import Trace, Stream, UTCDateTime, read\n",
        "from obspy.clients.fdsn import Client\n",
        "from sqlalchemy import create_engine, Column, Integer, String, Float, LargeBinary, ForeignKey\n",
        "from sqlalchemy.util import deprecations\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "import pickle\n",
        "\n",
        "#This database uses the version of SQLAlchemy compatible with Obspy as opposed to the newest version\n",
        "deprecations.SILENCE_UBER_WARNING = True\n",
        "#Environment Setup\n",
        "Base = declarative_base()\n",
        "client = Client(\"IRIS\")\n",
        "\n",
        "class Station(Base):\n",
        "    __tablename__ = 'stations'\n",
        "    station_id = Column(Integer, primary_key=True, autoincrement=True)\n",
        "    station = Column(String, nullable=False)\n",
        "    network = Column(String, nullable=False)\n",
        "    channel = Column(String, nullable=False)\n",
        "    latitude = Column(Float, nullable=True)\n",
        "    longitude = Column(Float, nullable=True)\n",
        "\n",
        "class WaveformTrace(Base):\n",
        "    __tablename__ = 'waveform_traces'\n",
        "    trace_id = Column(Integer, primary_key=True, autoincrement=True)\n",
        "    station_id = Column(Integer, ForeignKey('stations.station_id'), nullable=False)\n",
        "    start_time = Column(String, nullable=False)\n",
        "    end_time = Column(String, nullable=False)\n",
        "    trace_data = Column(LargeBinary, nullable=False)\n",
        "    sampling_rate = Column(Float, nullable=False)\n",
        "\n",
        "def setup_database():\n",
        "    #Creates database named \"sqlite:///seismic_data.db\"\n",
        "    #create_engine(\"sqlite:///:memory:\") could be used for faster processing but less scalability\n",
        "    #Remove seismic_data.db if it already exists\n",
        "\n",
        "    if os.path.exists(\"seismic_data.db\"):\n",
        "      os.remove(\"seismic_data.db\")\n",
        "    engine = create_engine(\"sqlite:///seismic_data.db\")\n",
        "    Base.metadata.create_all(engine)\n",
        "    Session = sessionmaker(bind=engine)\n",
        "    session = Session()\n",
        "    return engine, session\n",
        "\n",
        "def get_coordinates(station_name):\n",
        "    #Pulls coordinates from IRIS API using station name or user input if unavailable\n",
        "\n",
        "    latitude = None\n",
        "    longitude = None\n",
        "    try:\n",
        "        inventory = client.get_stations(station=station_name, level=\"station\")\n",
        "        station_info = inventory[0][0]\n",
        "        latitude = station_info.latitude\n",
        "        longitude = station_info.longitude\n",
        "    except:\n",
        "        print(f\"Unable to retrieve coordinates automatically:\")\n",
        "        while latitude is None:\n",
        "            try:\n",
        "                latitude = float(input(\"Enter latitude: \"))\n",
        "            except ValueError:\n",
        "              print(\"Invalid input. Please enter a numeric value for latitude.\")\n",
        "            while longitude is None:\n",
        "              try:\n",
        "                longitude = float(input(\"Enter longitude: \"))\n",
        "              except ValueError:\n",
        "                print(\"Invalid input. Please enter a numeric value for longitude.\")\n",
        "    return latitude, longitude\n",
        "\n",
        "def initialize_database(stream, session):\n",
        "    #Initialize database with stream and session\n",
        "\n",
        "    for trace in stream:\n",
        "        station_entry = session.query(Station).filter_by(\n",
        "            station=trace.stats.station, network=trace.stats.network\n",
        "        ).first()\n",
        "        #.mseed data may not have location\n",
        "        if not station_entry:\n",
        "            latitude = None\n",
        "            longitude = None\n",
        "\n",
        "            if hasattr(trace.stats, 'latitude') and hasattr(trace.stats, 'longitude'):\n",
        "                latitude = trace.stats.latitude\n",
        "                longitude = trace.stats.longitude\n",
        "            else:\n",
        "                #Search IRIS for station location\n",
        "                latitude, longitude = get_coordinates(trace.stats.station)\n",
        "\n",
        "            #Add station to database\n",
        "            station_entry = Station(\n",
        "                station=trace.stats.station,\n",
        "                network=trace.stats.network,\n",
        "                channel=trace.stats.channel,\n",
        "                latitude=latitude,\n",
        "                longitude=longitude\n",
        "            )\n",
        "            session.add(station_entry)\n",
        "            session.commit()\n",
        "\n",
        "        #Add each trace to the database\n",
        "        new_trace = WaveformTrace(\n",
        "            station_id=station_entry.station_id,\n",
        "            start_time=str(trace.stats.starttime),\n",
        "            end_time=str(trace.stats.endtime),\n",
        "            trace_data=pickle.dumps(trace.data),\n",
        "            sampling_rate=trace.stats.sampling_rate\n",
        "        )\n",
        "        session.add(new_trace)\n",
        "\n",
        "    session.commit()\n",
        "    print(\"Database initialized successfully.\")\n",
        "\n",
        "\n",
        "print(\"Database creation functions have been populated. Please proceed to the next step.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b1GDfOTHEev",
        "outputId": "38726ce6-5454-44ed-b5de-2c75061bb097"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database creation functions have been populated. Please proceed to the next step.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Unit Test Code**"
      ],
      "metadata": {
        "id": "4Hnt0icuHBgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "from obspy import Stream, read\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from sqlalchemy import create_engine\n",
        "import pickle\n",
        "from datetime import datetime\n",
        "import os\n",
        "\n",
        "def setup_database():\n",
        "    #Database setup from the previous code for unit tests\n",
        "\n",
        "    #Remove db if already exists for retesting\n",
        "    if os.path.exists(\"seismic_data.db\"):\n",
        "      os.remove(\"seismic_data.db\")\n",
        "    engine = create_engine(\"sqlite:///seismic_data.db\")\n",
        "    Base.metadata.create_all(engine)\n",
        "    Session = sessionmaker(bind=engine)\n",
        "    session = Session()\n",
        "    return engine, session\n",
        "\n",
        "class VerboseTestResult(unittest.TextTestResult):\n",
        "    #Add custom success and failure messages\n",
        "\n",
        "    def addSuccess(self, test):\n",
        "        super().addSuccess(test)\n",
        "        self.stream.writeln(f\"✔️ SUCCESS: {test.shortDescription() or str(test)}\")\n",
        "\n",
        "    def addFailure(self, test, err):\n",
        "        super().addFailure(test, err)\n",
        "        self.stream.writeln(f\"❌ FAILURE: {test.shortDescription() or str(test)}\")\n",
        "\n",
        "class VerboseTestRunner(unittest.TextTestRunner):\n",
        "    def _makeResult(self):\n",
        "        return VerboseTestResult(self.stream, self.descriptions, self.verbosity)\n",
        "\n",
        "class TestDatabase(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        #Setup database and session for each test\n",
        "        self.engine, self.session = setup_database()\n",
        "\n",
        "        #Load traces directly from .mseed files\n",
        "        self.stream = Stream()\n",
        "        for file in [\"SEP01.mseed\", \"SEP02.mseed\", \"SEP03.mseed\"]:\n",
        "            try:\n",
        "                self.stream += read(file)\n",
        "            except Exception as e:\n",
        "                print(f\"Error reading file {file}: {e}\")\n",
        "\n",
        "        #Initialize database with these traces\n",
        "        initialize_database(self.stream, self.session)\n",
        "\n",
        "    def test_full_trace_count(self):\n",
        "        \"Query by Full Trace Count\"\n",
        "\n",
        "        #Query database for all traces\n",
        "        traces = self.session.query(WaveformTrace).all()\n",
        "        #Verify all traces are in the database\n",
        "        self.assertEqual(len(traces), 32, \"All traces should be in the database\")\n",
        "\n",
        "    def test_query_by_time_range(self):\n",
        "        \"Query by Time Range\"\n",
        "\n",
        "        #Query based on a specific time range\n",
        "        start_time = \"2023-11-11T00:00:00.000001Z\"\n",
        "        end_time = \"2023-11-11T02:31:38.090001Z\"\n",
        "\n",
        "        traces = self.session.query(WaveformTrace).filter(\n",
        "            WaveformTrace.start_time >= start_time,\n",
        "            WaveformTrace.end_time <= end_time\n",
        "        ).all()\n",
        "\n",
        "        #Expected number of traces in this range\n",
        "        expected_count = 7\n",
        "        self.assertEqual(len(traces), expected_count, f\"Expected {expected_count} traces in the given time range.\")\n",
        "\n",
        "    def test_query_by_station(self):\n",
        "        \"Query by Station\"\n",
        "\n",
        "        #Query based on station name\n",
        "        station_name = \"SEP\"\n",
        "        traces = self.session.query(WaveformTrace).join(Station).filter(Station.station == station_name).all()\n",
        "\n",
        "        #Verify all traces belong to the station \"SEP\"\n",
        "        self.assertEqual(len(traces), 32, \"All 32 traces should belong to station 'SEP'.\")\n",
        "\n",
        "    def test_query_by_sampling_rate(self):\n",
        "        \"Query by Sampling Rate\"\n",
        "\n",
        "        #Query based on a specific sampling rate\n",
        "        sampling_rate = 100.0\n",
        "        traces = self.session.query(WaveformTrace).filter(WaveformTrace.sampling_rate == sampling_rate).all()\n",
        "\n",
        "        #Verify all traces have a sampling rate of 100.0 Hz\n",
        "        self.assertEqual(len(traces), 32, \"All 32 traces should have a sampling rate of 100.0 Hz.\")\n",
        "\n",
        "    def test_query_by_channel(self):\n",
        "        \"Query by Channel\"\n",
        "\n",
        "        #Query based on a specific channel\n",
        "        channel = \"EHZ\"\n",
        "        traces = self.session.query(WaveformTrace).join(Station).filter(Station.channel == channel).all()\n",
        "\n",
        "        #Verify all traces belong to the channel \"EHZ\"\n",
        "        self.assertEqual(len(traces), 32, \"All 32 traces should belong to channel 'EHZ'.\")\n",
        "\n",
        "    def test_query_by_location(self):\n",
        "        \"Query by Location\"\n",
        "\n",
        "        #Query based on station latitude and longitude\n",
        "        latitude = 46.19978\n",
        "        longitude = -122.190857\n",
        "        traces = self.session.query(WaveformTrace).join(Station).filter(\n",
        "            Station.latitude == latitude,\n",
        "            Station.longitude == longitude\n",
        "        ).all()\n",
        "\n",
        "        #Verify all traces have the correct coordinates\n",
        "        self.assertEqual(len(traces), 32, \"All traces should belong to the specified location.\")\n",
        "\n",
        "    def test_validate_trace_metadata(self):\n",
        "        \"Validation of Trace Metadata\"\n",
        "\n",
        "        #Query all traces\n",
        "        traces = self.session.query(WaveformTrace).all()\n",
        "\n",
        "        #Verify metadata for the first 7 traces\n",
        "        expected_values = [\n",
        "            (\"2023-11-11T00:00:00.000001Z\", \"2023-11-11T00:36:58.090001Z\", 100.0, 221810),\n",
        "            (\"2023-11-11T00:37:45.100001Z\", \"2023-11-11T01:41:06.090001Z\", 100.0, 380100),\n",
        "            (\"2023-11-11T01:43:07.100001Z\", \"2023-11-11T02:01:05.090001Z\", 100.0, 107800),\n",
        "            (\"2023-11-11T02:01:47.100001Z\", \"2023-11-11T02:02:10.090001Z\", 100.0, 2300),\n",
        "            (\"2023-11-11T02:02:24.100001Z\", \"2023-11-11T02:17:01.090001Z\", 100.0, 87700),\n",
        "            (\"2023-11-11T02:17:49.100001Z\", \"2023-11-11T02:31:16.090001Z\", 100.0, 80700),\n",
        "            (\"2023-11-11T02:31:37.100001Z\", \"2023-11-11T02:31:38.090001Z\", 100.0, 100)\n",
        "        ]\n",
        "\n",
        "        for trace, expected in zip(traces[:7], expected_values):\n",
        "            self.assertEqual(trace.start_time, expected[0], \"Start time does not match\")\n",
        "            self.assertEqual(trace.end_time, expected[1], \"End time does not match\")\n",
        "            self.assertEqual(trace.sampling_rate, expected[2], \"Sampling rate does not match\")\n",
        "            self.assertEqual(len(pickle.loads(trace.trace_data)), expected[3], \"Data length does not match\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    unittest.main(testRunner=VerboseTestRunner, argv=[''], exit=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGNXS0RdQg-c",
        "outputId": "069cdafa-e2f8-4b90-f8f8-d8bfd88badc8"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database initialized successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "✔️ SUCCESS: Query by Full Trace Count\n",
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database initialized successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "✔️ SUCCESS: Query by Channel\n",
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database initialized successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "✔️ SUCCESS: Query by Location\n",
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database initialized successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "✔️ SUCCESS: Query by Sampling Rate\n",
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database initialized successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "✔️ SUCCESS: Query by Station\n",
            "."
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database initialized successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "✔️ SUCCESS: Query by Time Range\n",
            ".✔️ SUCCESS: Validation of Trace Metadata\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 7 tests in 9.267s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Database initialized successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Visualization of Seismic Data**"
      ],
      "metadata": {
        "id": "lNhJcLSlKHf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Overview**"
      ],
      "metadata": {
        "id": "HTs20FBNbbTq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This section initializes visual creation functions. Be sure to run the **Visualization Code** section to set up the visualization functions for the current session. Using a combination of packages, including matplotlib for plotting helicorder charts and folium for creating interactive maps, this section ensures that seismic data is presented in a visually engaging and easy-to-understand format, with options for downloading the results.\n",
        "\n",
        "\n",
        "#### **Visualization Functions**\n",
        "\n",
        "1. **display_all**(station, stream)\n",
        "\n",
        "- Creates an interactive visualization for a seismic station's data, displaying metadata, a map, and helicorder plots for each unique day in separate tabs. Includes functionality to download each day's visualization as an HTML file.\n",
        "\n",
        "2. **create_metadata_chart**(station, daily_stream)\n",
        "\n",
        "- Generates an HTML widget displaying metadata for a given station and daily stream, including network, station, channel, coordinates, sampling rate, and trace count.\n",
        "\n",
        "3. **plot_helicorder**(station, stream, day)\n",
        "\n",
        "- Produces a helicorder plot for a specified day using ObsPy, formatting it with a title, axis labels, and gridlines. The plot is embedded as a base64-encoded PNG within an HTML widget.\n",
        "\n",
        "4. **create_map**(station)\n",
        "\n",
        "- Creates a folium map centered on the station's location, adding predefined nearby stations and a legend for marker types. Outputs the map as an HTML widget.\n",
        "\n",
        "5. **add_stations_to_map**(map_object, main_station_coords, main_station, distance=None)\n",
        "\n",
        "- Adds markers for predefined nearby stations (e.g., HOA and SUG) to the given folium map, including metadata such as coordinates and distance from the main station.\n",
        "\n",
        "6. **save_html_to_file**(content, filename=\"visualization_output.html\")\n",
        "\n",
        "- Saves HTML content to a specified file, enabling the visualization to be stored and shared.\n",
        "\n",
        "7. **create_download_button**(full_html, filename)\n",
        "\n",
        "- Generates a button widget that saves the provided HTML content to a file when clicked, allowing users to download visualizations directly.\n",
        "\n",
        "8. **visualize_from_query**(station_name, session, start_datetime=None, end_datetime=None)\n",
        "\n",
        "- Queries a database for seismic traces matching the given station and time range, then visualizes the results using the display_all function."
      ],
      "metadata": {
        "id": "dn-Yq1kxbgcX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Visualization Code**"
      ],
      "metadata": {
        "id": "TrIwDQfvbYwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from obspy import Trace, Stream, UTCDateTime, read\n",
        "from obspy.clients.fdsn import Client\n",
        "from sqlalchemy import create_engine, Column, Integer, String, Float, LargeBinary, ForeignKey\n",
        "from sqlalchemy.ext.declarative import declarative_base\n",
        "from sqlalchemy.orm import sessionmaker\n",
        "from geopy.distance import geodesic\n",
        "import pickle\n",
        "from IPython.display import display, clear_output, HTML\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import HTML, VBox, Tab, HBox, Layout, Button, Label\n",
        "import folium\n",
        "import io\n",
        "import base64\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "def visualize_from_query(station_name, session, start_datetime=None, end_datetime=None):\n",
        "    #Query database for data and generate seismic data visualization\n",
        "\n",
        "    station = session.query(Station).filter_by(station=station_name).first()\n",
        "    if not station:\n",
        "        print(\"Station not found in database.\")\n",
        "        return\n",
        "\n",
        "    traces = session.query(WaveformTrace).filter_by(station_id=station.station_id).all()\n",
        "    filtered_stream = Stream()\n",
        "\n",
        "    for trace in traces:\n",
        "        if start_datetime or end_datetime:\n",
        "            if start_datetime and UTCDateTime(trace.start_time) <= start_datetime:\n",
        "                continue\n",
        "            if end_datetime and UTCDateTime(trace.end_time) >= end_datetime:\n",
        "                continue\n",
        "        data = pickle.loads(trace.trace_data)\n",
        "        new_trace = Trace(data=data, header={\n",
        "            'starttime': UTCDateTime(trace.start_time),\n",
        "            'endtime': UTCDateTime(trace.end_time),\n",
        "            'station': station.station,\n",
        "            'network': station.network,\n",
        "            'sampling_rate': trace.sampling_rate\n",
        "        })\n",
        "        filtered_stream.append(new_trace)\n",
        "\n",
        "    if not filtered_stream:\n",
        "        print(\"No matching traces found.\")\n",
        "    else:\n",
        "        display_all(station, filtered_stream)\n",
        "\n",
        "def display_all(station, stream):\n",
        "    #Creates a html to display with tabs for each day including:\n",
        "    #Metadata, Map, and Helicorder\n",
        "\n",
        "    #Clears out output for better visualization\n",
        "    clear_output(wait=True)\n",
        "    #Generate tabs for each unique day\n",
        "    unique_days = {}\n",
        "    for trace in stream:\n",
        "        day = trace.stats.starttime.date\n",
        "        if day not in unique_days:\n",
        "            unique_days[day] = Stream()\n",
        "        unique_days[day].append(trace)\n",
        "\n",
        "    tabs = Tab()\n",
        "    tab_children = []\n",
        "    #Generate data for each day\n",
        "    for idx, (day, daily_stream) in enumerate(unique_days.items()):\n",
        "        # Create Metadata\n",
        "        metadata_widget = create_metadata_chart(station, daily_stream)\n",
        "        metadata_html = metadata_widget.value\n",
        "\n",
        "        # Create Map\n",
        "        map_widget = create_map(station)\n",
        "        map_html = map_widget.value\n",
        "\n",
        "        # Generate Helicorder Plot\n",
        "        helicorder_widget = plot_helicorder(station, daily_stream, day)\n",
        "        helicorder_html = helicorder_widget.value\n",
        "\n",
        "        #Combine all content into a single HTML and format appropriately\n",
        "        day_title = datetime.strptime(str(day), \"%Y-%m-%d\").strftime(\"%b %d %Y\")\n",
        "        day_filename = datetime.strptime(str(day), \"%Y-%m-%d\").strftime(\"%b_%d_%Y\")\n",
        "        full_html = f\"\"\"\n",
        "        <html>\n",
        "        <head>\n",
        "            <title>Seismic Data Visualization for {day_title}</title>\n",
        "            <style>\n",
        "                body {{ font-family: Arial, sans-serif; }}\n",
        "                .title {{ text-align: center; font-weight: bold; font-size: 24px; margin-top: 20px; }}\n",
        "                .metadata {{ float: left; width: 25%; padding: 10px; }}\n",
        "                .map {{ float: right; width: 70%;  padding: 10px; }}\n",
        "                .helicorder {{ clear: both; margin-top: 20px; text-align: center; }}\n",
        "            </style>\n",
        "        </head>\n",
        "        <body>\n",
        "            <div class=\"title\">Seismic Data Visualization for {day_title}</div>\n",
        "            <div class=\"metadata\">{metadata_html}</div>\n",
        "            <div class=\"map\">{map_html}</div>\n",
        "            <div class=\"helicorder\">{helicorder_html}</div>\n",
        "        </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "\n",
        "        #Create title and download button\n",
        "        download_button = create_download_button(full_html, f\"Seismic_Data_Visualization_{day_filename}.html\")\n",
        "        title_with_button = HBox([\n",
        "            HTML(value=f\"<h3 style='text-align: center; font-weight: bold; font-size: 20px; margin: 0;'>Seismic Data Visualization for {day_title}</h3>\"),\n",
        "            download_button\n",
        "        ], layout=Layout(justify_content=\"space-between\", align_items=\"center\", width=\"100%\"))\n",
        "\n",
        "        #Arrange layout so Metadata and Map are together with Helicorder below\n",
        "        metadata_widget.layout = Layout(\n",
        "            width=\"25%\",  # 25% width for metadata\n",
        "            height=\"100%\",\n",
        "            overflow=\"auto\"\n",
        "        )\n",
        "\n",
        "        map_widget.layout = Layout(\n",
        "            width=\"75%\",  # 75% width for the map\n",
        "            height=\"100%\",\n",
        "        )\n",
        "\n",
        "        tab_content = VBox([\n",
        "            title_with_button,\n",
        "            HBox([metadata_widget, map_widget]),\n",
        "            helicorder_widget\n",
        "        ])\n",
        "        tab_children.append(tab_content)\n",
        "\n",
        "    tabs.children = tab_children\n",
        "    for i, day in enumerate(unique_days.keys()):\n",
        "        day_title = datetime.strptime(str(day), \"%Y-%m-%d\").strftime(\"%b %d %Y\")\n",
        "        tabs.set_title(i, day_title)\n",
        "\n",
        "    display(tabs)\n",
        "\n",
        "def create_metadata_chart(station, daily_stream):\n",
        "    #Extract Metadata\n",
        "    start_time = min(trace.stats.starttime for trace in daily_stream)\n",
        "    end_time = max(trace.stats.endtime for trace in daily_stream)\n",
        "\n",
        "    #Create Metadata html with proper formatting\n",
        "    metadata_html = f'''\n",
        "    <div style=\"padding:0px; background-color:#f9f9f9; box-shadow:0 2px 5px rgba(0,0,0,0.1);border: 3px solid black; overflow: auto;\">\n",
        "        <table style=\"width:100%; border-spacing:0px; font-size:12px; line-height:2.08;\">\n",
        "            <tr><th colspan=\"2\" style=\"font-size:14px; margin-bottom:5px;\"><h3 style=\"margin:0;\">Station Metadata</h3></th></tr>\n",
        "            <tr><td><b>Network:</b></td><td>{station.network}</td></tr>\n",
        "            <tr><td><b>Station:</b></td><td>{station.station}</td></tr>\n",
        "            <tr><td><b>Channel:</b></td><td>{station.channel}</td></tr>\n",
        "            <tr><td><b>Coordinates:</b></td><td>({station.latitude}, {station.longitude})</td></tr>\n",
        "            <tr><td><b>Sampling Rate:</b></td><td>{daily_stream[0].stats.sampling_rate} Hz</td></tr>\n",
        "            <tr><td><b>Start Time:</b></td><td>{start_time}</td></tr>\n",
        "            <tr><td><b>End Time:</b></td><td>{end_time}</td></tr>\n",
        "            <tr><td><b>Trace Count:</b></td><td>{len(daily_stream)}</td></tr>\n",
        "        </table>\n",
        "    </div>\n",
        "    '''\n",
        "    return HTML(value=metadata_html)\n",
        "\n",
        "def plot_helicorder(station, stream, day):\n",
        "    #Generate the helicorder plot and format it using matplotlib\n",
        "\n",
        "    #Interpolate data linearly over gaps in traces and create dayplot\n",
        "    filled_stream = stream.merge(method=1, fill_value='interpolate')\n",
        "    fig = filled_stream.plot(type='dayplot',\n",
        "              interval=60,\n",
        "              method='',\n",
        "              one_tick_per_line=True,\n",
        "              time_axis_bottom=False,\n",
        "              linewidth = .5,\n",
        "              number_of_ticks=11,\n",
        "              size=(900, 1500),\n",
        "              title=\"\",\n",
        "              handle=True\n",
        "    )\n",
        "\n",
        "    day_title = datetime.strptime(str(day), \"%Y-%m-%d\").strftime(\"%b %d %Y\")\n",
        "\n",
        "    #Add Plot Titles and Labels\n",
        "    ax = fig.gca()\n",
        "    ax.set_title(\"Helicorder Plot for \" + station.station +'.' + station.network +\n",
        "                 '.' + station.channel + \" on \" + day_title, fontsize=18)\n",
        "    ax.set_xlabel(\"Time (Minutes)\", fontweight=\"bold\", fontsize=16)\n",
        "    ax.set_ylabel(\"UTC Time\", fontsize=16)\n",
        "    ax.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
        "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=10)\n",
        "    ax.tick_params(axis=\"both\", which=\"minor\", labelsize=8)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    #Add to buffer and encode\n",
        "    buffer = io.BytesIO()\n",
        "    plt.savefig(buffer, format='png', bbox_inches='tight')\n",
        "    buffer.seek(0)\n",
        "    base64_image = base64.b64encode(buffer.read()).decode('utf-8')\n",
        "    buffer.close()\n",
        "    plt.close(fig)\n",
        "\n",
        "\n",
        "    # Create an HTML element for the helicorder plot\n",
        "    helicorder_html = f'''\n",
        "    <div style=\"border: 3px solid black; margin-top: 0px;\">\n",
        "        <img src=\"data:image/png;base64,{base64_image}\" style=\"width: 100%; height: auto;\">\n",
        "    </div>\n",
        "    '''\n",
        "    return HTML(helicorder_html)\n",
        "\n",
        "def create_map(station):\n",
        "    #Create the map using folium\n",
        "\n",
        "    map_object = folium.Map(location=(station.latitude, station.longitude), zoom_start=10, zoom_control=False, height=\"100%\", width=\"100%\")\n",
        "    folium.Marker(\n",
        "        location=(station.latitude, station.longitude),\n",
        "        popup=(\n",
        "                    f\"<b>Station:<br></b> {station.station}<br>\"\n",
        "                    f\"<b>Network:<br></b> {station.network}<br>\"\n",
        "                    f\"<b>Coordinates:</b> ({round(station.latitude,3)}, {round(station.longitude,3)})<br>\"\n",
        "                ),\n",
        "        icon=folium.Icon(color=\"red\", icon=\"info-sign\")\n",
        "    ).add_to(map_object)\n",
        "\n",
        "    #Add additional stations to the map\n",
        "    add_stations_to_map(map_object, (station.latitude, station.longitude), station.station)\n",
        "\n",
        "    #Add legend\n",
        "    legend_html = '''\n",
        "      <div style=\"position: fixed;\n",
        "                  bottom: 0px; left: 0px; width: 150px; height: 90px;\n",
        "                  background-color: white; z-index:9999;\n",
        "                  border-top: 3px solid black; border-right: 3px solid black; padding:10px; font-size:12px;\n",
        "                  box-shadow:3px 3px 3px rgba(0,0,0,0.3);\">\n",
        "        <h4 style=\"margin:0;\">Legend</h4>\n",
        "        <p style=\"margin:0;\"><i style=\"color:red;\" class=\"fa fa-map-marker\"></i> Main Station</p>\n",
        "        <p style=\"margin:0;\"><i style=\"color:blue;\" class=\"fa fa-map-marker\"></i> Nearby Station</p>\n",
        "      </div>\n",
        "      '''\n",
        "    map_object.get_root().html.add_child(folium.Element(legend_html))\n",
        "\n",
        "    #Add and format title\n",
        "    title_html = '''\n",
        "    <div style=\"position: fixed; text-align: center; font-weight: bold;\n",
        "            top: 0px; left: 50%; transform: translate(-50%, 0);\n",
        "            z-index:9999; font-size:16px;\n",
        "            width: 100%; background:white; padding:5px 10px; border-bottom: 3px solid black;\">\n",
        "    <b>Station Map: SEP</b>\n",
        "    </div>\n",
        "    '''\n",
        "    map_object.get_root().html.add_child(folium.Element(title_html))\n",
        "\n",
        "\n",
        "    # Convert the map into an HTML widget\n",
        "    map_html = f'<div style=\"border: 3px solid black;\">{map_object._repr_html_()}</div>'\n",
        "    return HTML(value=map_html)\n",
        "\n",
        "def add_stations_to_map(map_object, main_station_coords, main_station):\n",
        "    #Add stations to the map\n",
        "\n",
        "    #Add IRIS client to pull data\n",
        "    client = Client(\"IRIS\")\n",
        "\n",
        "    #Predefined stations (HOA, SUG)\n",
        "    predefined_stations = [\n",
        "        {\"station\": \"HOA\", \"network\": \"CC\"},\n",
        "        {\"station\": \"SUG\", \"network\": \"CC\"}\n",
        "    ]\n",
        "\n",
        "    #Pull data from IRIS\n",
        "    for station in predefined_stations:\n",
        "        try:\n",
        "            inventory = client.get_stations(network=station[\"network\"], station=station[\"station\"])\n",
        "            station_info = inventory[0][0]\n",
        "            lat, lon = station_info.latitude, station_info.longitude\n",
        "            distance = geodesic(main_station_coords, (lat, lon)).miles\n",
        "            folium.Marker(\n",
        "                location=(lat, lon),\n",
        "                popup=(\n",
        "                    f\"<b>Station:</b> <br>{station['station']}<br>\"\n",
        "                    f\"<b>Network:</b> <br>{station['network']}<br>\"\n",
        "                    f\"<b>Coordinates:</b> ({round(lat,3)}, {round(lon,3)})<br>\"\n",
        "                    f\"<b>Distance to {main_station}</b> <br> {distance:.2f} miles\"\n",
        "                ),\n",
        "                icon=folium.Icon(color=\"blue\", icon=\"info-sign\")\n",
        "            ).add_to(map_object)\n",
        "        except Exception as e:\n",
        "            print(f\"Could not fetch data for station {station['station']}: {e}\")\n",
        "\n",
        "def save_html_to_file(content, filename):\n",
        "    #Save html to file for downloading visualization\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "def create_download_button(full_html, filename):\n",
        "    #Save html to file for downloading visualization\n",
        "\n",
        "    #Create event for downloading files instead of autodownloading them\n",
        "    def download_action(_):\n",
        "        save_html_to_file(full_html, filename)\n",
        "        print(f\"Saved {filename} for download.\")\n",
        "\n",
        "    button = Button(\n",
        "        description=\"Download\",\n",
        "        button_style=\"primary\",\n",
        "        tooltip=f\"Download {filename}\",\n",
        "        layout=Layout(width=\"100px\", height=\"30px\")\n",
        "    )\n",
        "    button.on_click(download_action)\n",
        "    return button\n",
        "\n",
        "print(\"Visualization functions have been populated. Please proceed to the next step.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "esRZNOrVKWnW",
        "outputId": "435ba2ae-7fd2-4d85-e970-83c9f2eb8625"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Visualization functions have been populated. Please proceed to the next step.\n"
          ]
        }
      ]
    }
  ]
}